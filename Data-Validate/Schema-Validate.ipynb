{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "import pymssql\n",
    "import json\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "parser = argparse.ArgumentParser(description='App to move check the schema of a dataset')\n",
    "\n",
    "parser.add_argument('-path', \n",
    "                    action=\"store\", \n",
    "                    dest=\"path\",\n",
    "                    type=str,\n",
    "                    default = 'schema.json',\n",
    "                    help=\"File path of schema.\")\n",
    "parser.add_argument('-db', \n",
    "                    action=\"store\", \n",
    "                    dest=\"db\",\n",
    "                    type=str,\n",
    "                    help=\"Datawarehouse db name.\")\n",
    "parser.add_argument('-schema', \n",
    "                    action=\"store\", \n",
    "                    dest=\"schema\",\n",
    "                    type=str,\n",
    "                    help=\"Datawarehouse schema name.\")\n",
    "parser.add_argument('-table', \n",
    "                    action=\"store\", \n",
    "                    dest=\"table\",\n",
    "                    type=str,\n",
    "                    help=\"Datawarehouse table name.\")\n",
    "\n",
    "path = 'test.json'\n",
    "\n",
    "with open(path, encoding='utf-8-sig') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "col_dict = data[r'col_names']\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load Data Warehouse Credentials\n",
    "host=os.getenv(\"host\")\n",
    "user=os.getenv(\"user\")\n",
    "password=os.getenv(\"password\")\n",
    "database=os.getenv(\"database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymssql.connect(host=host, user=user, password=password, database=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'Weights'\n",
    "schema = 'dbo'\n",
    "table = 'InspectionPriceVer'\n",
    "\n",
    "sql = \"\"\"SELECT TABLE_NAME, COLUMN_NAME, DATA_TYPE\n",
    "FROM {}.INFORMATION_SCHEMA.COLUMNS\n",
    "WHERE TABLE_NAME = '{}'\"\"\".format(db, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test = 'SELECT TOP 10 PERCENT * FROM {}.{}.{} order by newid()'.format(db, schema, table)\n",
    "random = pd.read_sql(random_test, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_dict:\n",
    "    test = df[df[r'COLUMN_NAME'] == col]\n",
    "    test = test.reset_index(drop=True)\n",
    "\n",
    "    if test.shape[0] == 0:\n",
    "        sys.exit('Expected column {} from dataset schema is missing.'.format(col))\n",
    "    else:\n",
    "        print('{} column is present.'.format(col))\n",
    "        \n",
    "    data_type_expected = str(col_dict[col]['type'])\n",
    "    data_type_actual = str(test[r'DATA_TYPE'][0])\n",
    "    \n",
    "    # Check for NA's\n",
    "    if 'na' in col_dict[col].keys():\n",
    "        if col_dict[col]['na'] == False:\n",
    "            if random[col].isnull().any():\n",
    "                sys.exit('{} column has NaN values, expected none.'.format(col))\n",
    "            else:\n",
    "                print('{} column has no NaN values, as expected.')\n",
    "    if data_type_expected in ('date', 'datetime'):\n",
    "        dt_format = col_dict[col][r'format']\n",
    "        try:\n",
    "            random[col] =  pd.to_datetime(random[col], format = dt_format)\n",
    "            print('{} column has the correct date format ({}).'.format(col, dt_format))\n",
    "        except: # catch *all* exceptions\n",
    "            e = repr(sys.exc_info())\n",
    "            sys.exit('Formatting Error: {}'.format(e))\n",
    "    elif data_type_actual != data_type_expected:\n",
    "        sys.exit('Column {} is {}, expected {}.'.format(col, data_type_actual, data_type_expected))\n",
    "    else:\n",
    "        print('{} column is the correct type ({}).'.format(col, data_type_expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict[r'StoreID'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random[r'StoreID'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
